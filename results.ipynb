{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "import qgrid\n",
    "\n",
    "\n",
    "def get_keychain_value_iter(d, key_chain=None):\n",
    "    key_chain = [] if key_chain is None else list(key_chain).copy()       \n",
    "    \n",
    "    if not isinstance(d, dict):\n",
    "        \n",
    "        yield tuple(key_chain), d\n",
    "    else:\n",
    "        for k, v in d.items():\n",
    "            yield from get_keychain_value_iter(v, key_chain + [k])\n",
    "            \n",
    "def get_keychain_value(d, key_chain):\n",
    "    \n",
    "    try:\n",
    "        for k in key_chain:\n",
    "            d = d[k]\n",
    "            \n",
    "    except Exception as ex:\n",
    "        raise KeyError() from ex\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cfg = {\n",
    "    'lr': float, \n",
    "    'lr_drop_fact': float, \n",
    "    'num_epochs': int,\n",
    "    'epoch_step': int,\n",
    "    'batch_size': int,\n",
    "    'weight_decay': float,\n",
    "    'validation_ratio': float, \n",
    "}\n",
    "\n",
    "model_cfg_meta = {\n",
    "    'model_type': 'PershomModel',\n",
    "    'model_kwargs': {\n",
    "        'use_sup_lvlset_filt': bool,\n",
    "        'filtration_kwargs': {\n",
    "            'use_node_deg': bool,\n",
    "            'use_node_lab': bool,\n",
    "            'num_gin': int,\n",
    "            'hidden_dim': int, \n",
    "            'use_mlp': bool\n",
    "        }, \n",
    "        'classifier_kwargs': {\n",
    "            'num_struct_elem': int\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "exp_cfg_meta = {\n",
    "    'dataset_name': str, \n",
    "    'training': training_cfg, \n",
    "    'model': model_cfg_meta\n",
    "}\n",
    "\n",
    "exp_res_meta = {\n",
    "    'exp_cfg': exp_cfg_meta, \n",
    "    'cv_test_acc': list, \n",
    "    'cv_val_acc': list, \n",
    "    'cv_indices_trn_tst_val': list, \n",
    "    'cv_epoch_loss': list,\n",
    "    'start_time': list, \n",
    "    'id': str    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc = {k: k[-1] for k, v in list(get_keychain_value_iter(exp_res_meta))}\n",
    "kc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NAMES = {\n",
    " ('exp_cfg', 'dataset_name'): 'dataset_name',\n",
    "#  ('exp_cfg', 'training', 'lr'): 'lr',\n",
    "#  ('exp_cfg', 'training', 'lr_drop_fact'): 'lr_drop_fact',\n",
    " ('exp_cfg', 'training', 'num_epochs'): 'num_epochs',\n",
    "#  ('exp_cfg', 'training', 'epoch_step'): 'epoch_step',\n",
    "#  ('exp_cfg', 'training', 'batch_size'): 'batch_size',\n",
    "#  ('exp_cfg', 'training', 'weight_decay'): 'weight_decay',\n",
    "    \n",
    "#  ('exp_cfg', 'training', 'validation_ratio'): 'validation_ratio',\n",
    "    \n",
    "#  ('exp_cfg', 'model', 'model_type'): 'model_type',\n",
    " ('exp_cfg',\n",
    "  'model',\n",
    "  'model_kwargs',\n",
    "  'use_sup_lvlset_filt'): 'use_sup_lvlset_filt',\n",
    " ('exp_cfg',\n",
    "  'model',\n",
    "  'model_kwargs',\n",
    "  'filtration_kwargs',\n",
    "  'use_node_deg'): 'use_node_deg',\n",
    " ('exp_cfg',\n",
    "  'model',\n",
    "  'model_kwargs',\n",
    "  'filtration_kwargs',\n",
    "  'use_node_lab'): 'use_node_lab',\n",
    "#  ('exp_cfg',\n",
    "#   'model',\n",
    "#   'model_kwargs',\n",
    "#   'filtration_kwargs',\n",
    "#   'num_gin'): 'num_gin',\n",
    " ('exp_cfg',\n",
    "  'model',\n",
    "  'model_kwargs',\n",
    "  'filtration_kwargs',\n",
    "  'hidden_dim'): 'hidden_dim',\n",
    " ('exp_cfg',\n",
    "  'model',\n",
    "  'model_kwargs',\n",
    "  'filtration_kwargs',\n",
    "  'use_mlp'): 'use_mlp',\n",
    " ('exp_cfg',\n",
    "  'model',\n",
    "  'model_kwargs',\n",
    "  'classifier_kwargs',\n",
    "  'num_struct_elem'): 'num_struct_elem',\n",
    "#  ('cv_test_acc',): 'cv_test_acc',\n",
    "#  ('cv_val_acc'): 'cv_val_acc',\n",
    "#  ('cv_indices_trn_tst_val',): 'cv_indices_trn_tst_val', # may not be existent in older versions\n",
    "#  ('cv_epoch_loss',): 'cv_epoch_loss',\n",
    "#  ('start_time',): 'start_time',\n",
    "#  ('id',): 'id'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    files = glob.glob(os.path.join(path, \"*.pickle\"))\n",
    "    res = []\n",
    "    for f in files: \n",
    "        res.append(pickle.load(open(f, 'rb')))\n",
    "\n",
    "    print(\"# Found\", len(res), \"files.\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def pd_frame(path):\n",
    "    \n",
    "    f = read_files(path)\n",
    "    \n",
    "    data_frames = []\n",
    "    for i, res in enumerate(f):\n",
    "        row = {}\n",
    "        finished_training = (len(res['cv_test_acc'][-1]) == res['exp_cfg']['training']['num_epochs'])\n",
    "        \n",
    "        row['finished_training'] = finished_training\n",
    "            \n",
    "        cv_acc = [x[-1] for x in res['cv_test_acc'] if len(x) > 0]\n",
    "        \n",
    "        row['cv_test_acc_last_mean'] = np.mean(cv_acc)\n",
    "        row['cv_test_acc_last_std'] = np.std(cv_acc)\n",
    "        \n",
    "        for k, v in COL_NAMES.items():\n",
    "            try:\n",
    "                row[v] = get_keychain_value(res, k)\n",
    "            except KeyError:\n",
    "                pass\n",
    "    \n",
    "        \n",
    "#         print(row)\n",
    "        f = pd.DataFrame(row, index=[i])\n",
    "        \n",
    "        data_frames.append(f)\n",
    "        \n",
    "        \n",
    "    return pd.concat(data_frames, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './results/'\n",
    "RES = pd_frame(path)\n",
    "qgrid_widget = qgrid.show_grid(RES, show_toolbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
