{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import glob\n",
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "import qgrid\n",
    "import core.train_engine\n",
    "\n",
    "\n",
    "def get_keychain_value_iter(d, key_chain=None):\n",
    "    key_chain = [] if key_chain is None else list(key_chain).copy()       \n",
    "    \n",
    "    if not isinstance(d, dict):\n",
    "        \n",
    "        yield tuple(key_chain), d\n",
    "    else:\n",
    "        for k, v in d.items():\n",
    "            yield from get_keychain_value_iter(v, key_chain + [k])\n",
    "            \n",
    "def get_keychain_value(d, key_chain):\n",
    "    \n",
    "    try:\n",
    "        for k in key_chain:\n",
    "            d = d[k]\n",
    "            \n",
    "    except Exception as ex:\n",
    "        raise KeyError() from ex\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cfg = {\n",
    "    'lr': float, \n",
    "    'lr_drop_fact': float, \n",
    "    'num_epochs': int,\n",
    "    'epoch_step': int,\n",
    "    'batch_size': int,\n",
    "    'weight_decay': float,\n",
    "    'validation_ratio': float, \n",
    "}\n",
    "\n",
    "model_cfg_meta = {\n",
    "    'model_type': 'PershomModel',\n",
    "    'model_kwargs': {\n",
    "        'use_sup_lvlset_filt': bool,\n",
    "        'filtration_kwargs': {\n",
    "            'use_node_deg': bool,\n",
    "            'use_node_lab': bool,\n",
    "            'num_gin': int,\n",
    "            'hidden_dim': int, \n",
    "            'use_mlp': bool\n",
    "        }, \n",
    "        'classifier_kwargs': {\n",
    "            'num_struct_elem': int\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "exp_cfg_meta = {\n",
    "    'dataset_name': str, \n",
    "    'training': training_cfg, \n",
    "    'model': model_cfg_meta\n",
    "}\n",
    "\n",
    "exp_res_meta = {\n",
    "    'exp_cfg': exp_cfg_meta, \n",
    "    'cv_test_acc': list, \n",
    "    'cv_val_acc': list, \n",
    "    'cv_indices_trn_tst_val': list, \n",
    "    'cv_epoch_loss': list,\n",
    "    'start_time': list, \n",
    "    'id': str    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('exp_cfg', 'dataset_name'): 'dataset_name',\n",
       " ('exp_cfg', 'training', 'lr'): 'lr',\n",
       " ('exp_cfg', 'training', 'lr_drop_fact'): 'lr_drop_fact',\n",
       " ('exp_cfg', 'training', 'num_epochs'): 'num_epochs',\n",
       " ('exp_cfg', 'training', 'epoch_step'): 'epoch_step',\n",
       " ('exp_cfg', 'training', 'batch_size'): 'batch_size',\n",
       " ('exp_cfg', 'training', 'weight_decay'): 'weight_decay',\n",
       " ('exp_cfg', 'training', 'validation_ratio'): 'validation_ratio',\n",
       " ('exp_cfg', 'model', 'model_type'): 'model_type',\n",
       " ('exp_cfg',\n",
       "  'model',\n",
       "  'use_super_level_set_filtration'): 'use_super_level_set_filtration',\n",
       " ('exp_cfg', 'model', 'use_node_degree'): 'use_node_degree',\n",
       " ('exp_cfg', 'model', 'use_node_label'): 'use_node_label',\n",
       " ('exp_cfg', 'model', 'gin_number'): 'gin_number',\n",
       " ('exp_cfg', 'model', 'gin_dimension'): 'gin_dimension',\n",
       " ('exp_cfg', 'model', 'gin_mlp_type'): 'gin_mlp_type',\n",
       " ('exp_cfg', 'model', 'num_struct_elements'): 'num_struct_elements',\n",
       " ('cv_test_acc',): 'cv_test_acc',\n",
       " ('cv_val_acc',): 'cv_val_acc',\n",
       " ('cv_indices_trn_tst_val',): 'cv_indices_trn_tst_val',\n",
       " ('cv_epoch_loss',): 'cv_epoch_loss',\n",
       " ('start_time',): 'start_time',\n",
       " ('id',): 'id'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc = {k: k[-1] for k, v in list(get_keychain_value_iter(core.train_engine.__exp_res_meta))}\n",
    "kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NAMES = {\n",
    "    ('exp_cfg', 'dataset_name'): 'dataset_name',\n",
    "#     ('exp_cfg', 'training', 'lr'): 'lr',\n",
    "#     ('exp_cfg', 'training', 'lr_drop_fact'): 'lr_drop_fact',\n",
    "#     ('exp_cfg', 'training', 'num_epochs'): 'num_epochs',\n",
    "#     ('exp_cfg', 'training', 'epoch_step'): 'epoch_step',\n",
    "#     ('exp_cfg', 'training', 'batch_size'): 'batch_size',\n",
    "#     ('exp_cfg', 'training', 'weight_decay'): 'weight_decay',\n",
    "#     ('exp_cfg', 'training', 'validation_ratio'): 'validation_ratio',\n",
    "    ('exp_cfg', 'model', 'model_type'): 'model_type',\n",
    "    ('exp_cfg', 'model', 'use_super_level_set_filtration'): 'use_super_level_set_filtration',\n",
    "    ('exp_cfg', 'model', 'use_node_degree'): 'use_node_degree',\n",
    "    ('exp_cfg', 'model', 'use_node_label'): 'use_node_label',\n",
    "    ('exp_cfg', 'model', 'gin_number'): 'gin_number',\n",
    "    ('exp_cfg', 'model', 'gin_dimension'): 'gin_dimension',\n",
    "    ('exp_cfg', 'model', 'gin_mlp_type'): 'gin_mlp_type',\n",
    "    ('exp_cfg', 'model', 'num_struct_elements'): 'num_struct_elements',\n",
    "#     ('cv_test_acc',): 'cv_test_acc',\n",
    "#     ('cv_val_acc',): 'cv_val_acc',\n",
    "#     ('cv_indices_trn_tst_val',): 'cv_indices_trn_tst_val',\n",
    "#     ('cv_epoch_loss',): 'cv_epoch_loss',\n",
    "#     ('start_time',): 'start_time',\n",
    "#     ('id',): 'id',\n",
    "    ('finished_training',): 'finished_training'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    files = glob.glob(os.path.join(path, \"*.pickle\"))\n",
    "    res = []\n",
    "    for f in files: \n",
    "        res.append(pickle.load(open(f, 'rb')))\n",
    "\n",
    "    print(\"# Found\", len(res), \"files.\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def pd_frame(path):\n",
    "    \n",
    "    f = read_files(path)\n",
    "    \n",
    "    data_frames = []\n",
    "    for i, res in enumerate(f):\n",
    "        row = {}\n",
    "            \n",
    "        cv_acc_last = [x[-1] for x in res['cv_test_acc'] if len(x) > 0]\n",
    "        \n",
    "        row['acc_last_mean'] = np.mean(cv_acc_last)\n",
    "        row['acc_last_std'] = np.std(cv_acc_last)\n",
    "        \n",
    "        cv_acc_validated = []\n",
    "        for test, val in zip(res['cv_test_acc'], res['cv_val_acc']):\n",
    "            if not len(test) == res['exp_cfg']['training']['num_epochs']:\n",
    "                continue\n",
    "            n = len(test)//2\n",
    "            test = torch.tensor(test[n:])\n",
    "            val = torch.tensor(val[n:])\n",
    "            \n",
    "            _, i_max = val.max(0)\n",
    "            cv_acc_validated.append(test[i_max].item())\n",
    "            \n",
    "        row['acc_val_mean'] = np.mean(cv_acc_validated)\n",
    "        row['acc_val_std'] = np.std(cv_acc_validated)\n",
    "        \n",
    "        \n",
    "        cv_folds_available = sum([1 for cv in res['cv_test_acc'] if len(cv) == res['exp_cfg']['training']['num_epochs']])\n",
    "        row['cv_folds_available'] = cv_folds_available\n",
    "        \n",
    "        \n",
    "        for k, v in COL_NAMES.items():\n",
    "            try:\n",
    "                row[v] = get_keychain_value(res, k)\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        f = pd.DataFrame(row, index=[i])\n",
    "        \n",
    "        data_frames.append(f)\n",
    "        \n",
    "        \n",
    "    return pd.concat(data_frames, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Found 21 files.\n"
     ]
    }
   ],
   "source": [
    "path = './results/'\n",
    "RES = pd_frame(path)\n",
    "qgrid_widget = qgrid.show_grid(RES, show_toolbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fc06e8808c43dda9eeb0c43336a46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defauâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid_widget.get_changed_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells contain some utility for messing around with results, i.e., deleting etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(os.path.join(path, \"*.pickle\"))\n",
    "# for f in files:     \n",
    "#     with open(f, 'rb') as fid:\n",
    "#         res = pickle.load(fid)\n",
    "#     finished_training = (len(res['cv_test_acc'][-1]) == res['exp_cfg']['training']['num_epochs'])\n",
    "#     res['finished_training'] = finished_training\n",
    "    \n",
    "#     with open(f, 'wb') as fid:\n",
    "#         pickle.dump(obj=res, file=fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
