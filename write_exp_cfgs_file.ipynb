{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /tmp/chofer_torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /tmp/chofer_torch_extensions/pershom_cuda_ext/build.ninja...\n",
      "Building extension module pershom_cuda_ext...\n",
      "Loading extension module pershom_cuda_ext...\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import itertools\n",
    "import copy\n",
    "import uuid\n",
    "import pickle\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import chofer_torchex.pershom as pershom\n",
    "\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "\n",
    "from chofer_torchex import pershom\n",
    "ph = pershom.pershom_backend.__C.VertFiltCompCuda__vert_filt_persistence_batch\n",
    "\n",
    "from chofer_torchex.nn import SLayerRationalHat\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "import core.model\n",
    "from core.data import dataset_factory\n",
    "from core.utils import my_collate, evaluate\n",
    "from core.train_engine import *\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pma/chofer/repositories/pytorch_geometric/build/lib/torch_geometric/data/data.py:175: UserWarning: The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n",
      "  warnings.warn(__num_nodes_warn_msg__.format('edge'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'REDDIT-BINARY': False, 'REDDIT-MULTI-5K': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names = [\n",
    "        'REDDIT-BINARY',\n",
    "        'REDDIT-MULTI-5K',\n",
    "#         'COLLAB',\n",
    "        #'IMDB-MULTI',\n",
    "        #'IMDB-BINARY',\n",
    "         #'ENZYMES',\n",
    "         #'PTC_PGNN',\n",
    "         #'PTC_FM',\n",
    "         #'PTC_FR',\n",
    "         #'PTC_MM',\n",
    "         #'PTC_MR',\n",
    "         #'PROTEINS',\n",
    "         #'DD',\n",
    "         #'NCI1',\n",
    "         #'MUTAG'\n",
    "]\n",
    "\n",
    "dataset_has_node_lab = {n: dataset_factory(n, verbose=False).num_node_lab is not None for n in dataset_names}\n",
    "dataset_has_node_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cfg = {\n",
    "    'lr': 0.01, \n",
    "    'lr_drop_fact': 0.5, \n",
    "    'num_epochs': 100,\n",
    "    'epoch_step': 20,\n",
    "    'batch_size': 32,\n",
    "    'weight_decay': 10e-06,\n",
    "    'validation_ratio': 0.1\n",
    "}\n",
    "training_cfgs = [training_cfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pershom rigid filtration ...\n",
    "proto = {\n",
    "    'model_type': 'PershomRigidDegreeFilt',\n",
    "    'use_super_level_set_filtration': None, \n",
    "    'num_struct_elements': 100, \n",
    "    'cls_hidden_dimension': 64, \n",
    "    'drop_out': 0.0\n",
    "}\n",
    "model_cfgs_PershomRigidDegreeFilt = []\n",
    "#for b in [False, True]:\n",
    "for b in [True]:\n",
    "    tmp = copy.deepcopy(proto)\n",
    "    \n",
    "    tmp['use_super_level_set_filtration'] = b\n",
    "    \n",
    "    model_cfgs_PershomRigidDegreeFilt.append(tmp)\n",
    "    \n",
    "len(model_cfgs_PershomRigidDegreeFilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pershom learnt filtration ...\n",
    "proto = {\n",
    "    'model_type': 'PershomLearnedFilt',\n",
    "    'use_super_level_set_filtration': None, \n",
    "    'use_node_degree': None, \n",
    "    'set_node_degree_uninformative': True, \n",
    "    'use_node_label': None, \n",
    "    'gin_number': 1, \n",
    "    'gin_dimension': 64,\n",
    "    'gin_mlp_type': 'lin_bn_lrelu_lin', \n",
    "    'num_struct_elements': 100, \n",
    "    'cls_hidden_dimension': 64, \n",
    "    'drop_out': 0.0   \n",
    "}\n",
    "model_cfgs_PershomLearnedFilt = []\n",
    "\n",
    "B = [(True, True), (False, True), (True, False)]\n",
    "\n",
    "for (a, b), c, d, e in itertools.product(B, [True], [64], [1]):\n",
    "    tmp = copy.deepcopy(proto)\n",
    "\n",
    "    tmp['use_node_degree'] = a\n",
    "    tmp['use_node_label']  = b\n",
    "    tmp['use_super_level_set_filtration'] = c    \n",
    "\n",
    "    tmp['gin_dimension'] = d\n",
    "    tmp['gin_number'] = e\n",
    "\n",
    "    model_cfgs_PershomLearnedFilt.append(tmp)\n",
    "    \n",
    "len(model_cfgs_PershomLearnedFilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GIN ... \n",
    "proto = {\n",
    "    'model_type': 'GIN',\n",
    "    'use_node_degree': None, \n",
    "    'use_node_label': None, \n",
    "    'gin_number': None, \n",
    "    'gin_dimension': 64,\n",
    "    'gin_mlp_type': 'lin_bn_lrelu_lin', \n",
    "    'cls_hidden_dimension': 64, \n",
    "    'set_node_degree_uninformative': None,\n",
    "    'pooling_strategy': 'sort',\n",
    "    'drop_out': 0.5 \n",
    "}\n",
    "model_cfgs_GIN = []\n",
    "\n",
    "B = [(True, True), (False, True), (True, False)]\n",
    "\n",
    "for (a, b), c, d in itertools.product(B, [1], [True]):\n",
    "    tmp = copy.deepcopy(proto)\n",
    "\n",
    "    tmp['use_node_degree'] = a\n",
    "    tmp['use_node_label'] = b\n",
    "    tmp['gin_number'] = c\n",
    "    tmp['set_node_degree_uninformative'] = d\n",
    "\n",
    "    model_cfgs_GIN.append(tmp)\n",
    "    \n",
    "len(model_cfgs_GIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SimpleNNBaseline ... \n",
    "proto = {\n",
    "    'model_type': 'SimpleNNBaseline',\n",
    "    'use_node_degree': None, \n",
    "    'use_node_label': None, \n",
    "    'gin_dimension': 64,\n",
    "    'gin_mlp_type': 'lin_bn_lrelu_lin', \n",
    "    'cls_hidden_dimension': 64, \n",
    "    'set_node_degree_uninformative': None,\n",
    "    'pooling_strategy': 'sum',\n",
    "    'drop_out': None \n",
    "}\n",
    "model_cfgs_SimpleNNBaseline = []\n",
    "\n",
    "B = [(True, True), (False, True), (True, False)]\n",
    "\n",
    "for (a, b), c, d in itertools.product(B, [False], [0.0, 0.5]):\n",
    "    tmp = copy.deepcopy(proto)\n",
    "\n",
    "    tmp['use_node_degree'] = a\n",
    "    tmp['use_node_label'] = b\n",
    "    tmp['set_node_degree_uninformative'] = c\n",
    "    tmp['drop_out'] = d\n",
    "\n",
    "    model_cfgs_SimpleNNBaseline.append(tmp)\n",
    "    \n",
    "len(model_cfgs_SimpleNNBaseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(dataset_names, training_cfgs, model_cfgs, tag=\"\"):\n",
    "    exp_cfgs = []\n",
    "    continued = 0\n",
    "    for a, b, c in itertools.product(dataset_names, training_cfgs, model_cfgs):\n",
    "\n",
    "        # filter out datasets which have no node labels\n",
    "        ds_has_node_lab = dataset_has_node_lab[a]\n",
    "\n",
    "        if 'use_node_label' in c:\n",
    "            use_node_lab = c['use_node_label']\n",
    "\n",
    "            if (not ds_has_node_lab) and use_node_lab:\n",
    "#                 print(a, c['model_type'])\n",
    "                continue\n",
    "\n",
    "        tmp = {\n",
    "            'dataset_name': a, \n",
    "            'training': b, \n",
    "            'model': c, \n",
    "            'tag': tag\n",
    "        }\n",
    "        exp_cfgs.append(tmp)\n",
    "        \n",
    "    return exp_cfgs\n",
    "\n",
    "def write_file(dataset_names, training_cfgs, model_cfgs, output_dir, tag=\"\", file_name=None):\n",
    "    exp_cfgs = combine(dataset_names, training_cfgs, model_cfgs, tag=tag)\n",
    "    if file_name is None:\n",
    "        file_name = \"exp_cfgs__\" + \"_\".join(dataset_names) + \".json\"\n",
    "        \n",
    "    with open(os.path.join(output_dir, file_name), 'w') as fid:\n",
    "        json.dump(exp_cfgs, fid)\n",
    "        \n",
    "    print('Num cfgs: ', len(exp_cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/pma/chofer/repositories/nips_2019_code/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cfgs:  2\n"
     ]
    }
   ],
   "source": [
    "write_file(dataset_names, \n",
    "           training_cfgs, \n",
    "           model_cfgs_GIN,\n",
    "           output_dir, \n",
    "           file_name='exp_cfg_REDDIT_uninformative_SortPooling.json', \n",
    "           tag=\"1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_cfgs = combine(dataset_names, \n",
    "#                    training_cfgs,\n",
    "#                    model_cfgs_PershomRigidDegreeFilt)\n",
    "# print(len(exp_cfgs))\n",
    "# with open(os.path.join(output_dir, 'exp_cfgs_rigid_degree_filtration.json'), 'w') as fid:\n",
    "#     json.dump(exp_cfgs, fid)\n",
    "    \n",
    "    \n",
    "# exp_cfgs = combine(dataset_names, \n",
    "#                    training_cfgs,\n",
    "#                    model_cfgs_PershomLearnedFilt)\n",
    "# print(len(exp_cfgs))\n",
    "# with open(os.path.join(output_dir, 'exp_cfgs_learnt_filtration.json'), 'w') as fid:\n",
    "#     json.dump(exp_cfgs, fid)\n",
    "\n",
    "    \n",
    "# exp_cfgs = combine(dataset_names, \n",
    "#                    training_cfgs,\n",
    "#                    model_cfgs_GIN)\n",
    "# print(len(exp_cfgs))\n",
    "# with open(os.path.join(output_dir, 'exp_cfgs_learnt_filtration.json'), 'w') as fid:\n",
    "#     json.dump(exp_cfgs, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = combine(dataset_names, training_cfgs, model_cfgs_PershomRigidDegreeFilt)\n",
    "print(len(cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for c in cfgs:\n",
    "#     experiment(c, device='cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
