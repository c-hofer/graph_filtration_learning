{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /tmp/chofer_torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /tmp/chofer_torch_extensions/pershom_cuda_ext/build.ninja...\n",
      "Building extension module pershom_cuda_ext...\n",
      "Loading extension module pershom_cuda_ext...\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import itertools\n",
    "import copy\n",
    "import uuid\n",
    "import pickle\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import chofer_torchex.pershom as pershom\n",
    "\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "\n",
    "from chofer_torchex import pershom\n",
    "ph = pershom.pershom_backend.__C.VertFiltCompCuda__vert_filt_persistence_batch\n",
    "\n",
    "from chofer_torchex.nn import SLayerRationalHat\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "import core.model\n",
    "from core.data import dataset_factory\n",
    "from core.utils import my_collate, evaluate\n",
    "from core.train_engine import *\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NCI1': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_names = [\n",
    "#         'COLLAB',\n",
    "#         'IMDB-MULTI',\n",
    "#         'IMDB-BINARY',\n",
    "#         'ENZYMES',\n",
    "        #'PTC_PGNN',\n",
    "        #'PTC_FM',\n",
    "        #'PTC_FR',\n",
    "        #'PTC_MM',\n",
    "        #'PTC_MR',\n",
    "#         'PROTEINS',\n",
    "#         'DD',\n",
    "        'NCI1',\n",
    "        #'MUTAG'\n",
    "]\n",
    "\n",
    "dataset_has_node_lab = {n: dataset_factory(n, verbose=False).num_node_lab is not None for n in dataset_names}\n",
    "dataset_has_node_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cfg = {\n",
    "    'lr': 0.01, \n",
    "    'lr_drop_fact': 0.5, \n",
    "    'num_epochs': 100, \n",
    "    'epoch_step': 20,\n",
    "    'batch_size': 64,\n",
    "    'weight_decay': 10e-06,\n",
    "    'validation_ratio': 0.1\n",
    "}\n",
    "training_cfgs = [training_cfg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto = {\n",
    "    'model_type': 'PershomRigidDegreeFilt',\n",
    "    'use_super_level_set_filtration': None, \n",
    "    'num_struct_elements': 100, \n",
    "}\n",
    "model_cfgs_PershomRigidDegreeFilt = []\n",
    "for b in [False, True]:\n",
    "    tmp = copy.deepcopy(proto)\n",
    "    \n",
    "    tmp['use_super_level_set_filtration'] = b\n",
    "    \n",
    "    model_cfgs_PershomRigidDegreeFilt.append(tmp)\n",
    "    \n",
    "len(model_cfgs_PershomRigidDegreeFilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto = {\n",
    "    'model_type': 'PershomLearnedFilt',\n",
    "    'use_super_level_set_filtration': None, \n",
    "    'use_node_degree': None, \n",
    "    'use_node_label': None, \n",
    "    'gin_number': 1, \n",
    "    'gin_dimension': 64,\n",
    "    'gin_mlp_type': 'lin_bn_lrelu_lin', \n",
    "    'num_struct_elements': 100, \n",
    "}\n",
    "model_cfgs_PershomLearnedFilt = []\n",
    "\n",
    "B = [(True, True), (False, True), (True, False)]\n",
    "\n",
    "for (a, b), c in itertools.product(B, [True, False]):\n",
    "    tmp = copy.deepcopy(proto)\n",
    "\n",
    "    tmp['use_node_degree'] = a\n",
    "    tmp['use_node_label'] = b\n",
    "    tmp['use_super_level_set_filtration'] = c    \n",
    "\n",
    "    model_cfgs_PershomLearnedFilt.append(tmp)\n",
    "    \n",
    "len(model_cfgs_PershomLearnedFilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto = {\n",
    "    'model_type': 'GIN',\n",
    "    'use_node_degree': None, \n",
    "    'use_node_label': None, \n",
    "    'gin_number': 5, \n",
    "    'gin_dimension': 64,\n",
    "    'gin_mlp_type': 'lin_bn_lrelu_lin', \n",
    "}\n",
    "model_cfgs_GIN = []\n",
    "\n",
    "B = [(True, True), (False, True), (True, False)]\n",
    "\n",
    "for a, b in B:\n",
    "    tmp = copy.deepcopy(proto)\n",
    "\n",
    "    tmp['use_node_degree'] = a\n",
    "    tmp['use_node_label'] = b\n",
    "\n",
    "    model_cfgs_GIN.append(tmp)\n",
    "    \n",
    "len(model_cfgs_GIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(dataset_names, training_cfgs, model_cfgs):\n",
    "    exp_cfgs = []\n",
    "    continued = 0\n",
    "    for a, b, c in itertools.product(dataset_names, training_cfgs, model_cfgs):\n",
    "\n",
    "        # filter out datasets which have no node labels\n",
    "        ds_has_node_lab = dataset_has_node_lab[a]\n",
    "\n",
    "        if 'use_node_label' in c:\n",
    "            use_node_lab = c['use_node_label']\n",
    "\n",
    "            if (not ds_has_node_lab) and use_node_lab:\n",
    "#                 print(a, c['model_type'])\n",
    "                continue\n",
    "\n",
    "        tmp = {\n",
    "            'dataset_name': a, \n",
    "            'training': b, \n",
    "            'model': c\n",
    "        }\n",
    "        exp_cfgs.append(tmp)\n",
    "        \n",
    "    return exp_cfgs\n",
    "\n",
    "def write_file(dataset_names, training_cfgs, model_cfgs, output_dir):\n",
    "    exp_cfgs = combine(dataset_names, training_cfgs, model_cfgs)\n",
    "    file_name = \"exp_cfgs__\" + \"_\".join(dataset_names) + \".json\"\n",
    "    with open(os.path.join(output_dir, file_name), 'w') as fid:\n",
    "        json.dump(exp_cfgs, fid)\n",
    "        \n",
    "    print('Num cfgs: ', len(exp_cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cfgs:  6\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/home/pma/chofer/repositories/nips_2019_code/results'\n",
    "\n",
    "write_file(dataset_names, training_cfgs, model_cfgs_PershomLearnedFilt, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "exp_cfgs = combine(dataset_names, \n",
    "                   training_cfgs,\n",
    "                   model_cfgs_PershomRigidDegreeFilt)\n",
    "print(len(exp_cfgs))\n",
    "with open(os.path.join(output_dir, 'exp_cfgs_rigid_degree_filtration.json'), 'w') as fid:\n",
    "    json.dump(exp_cfgs, fid)\n",
    "    \n",
    "    \n",
    "exp_cfgs = combine(dataset_names, \n",
    "                   training_cfgs,\n",
    "                   model_cfgs_PershomLearnedFilt)\n",
    "print(len(exp_cfgs))\n",
    "with open(os.path.join(output_dir, 'exp_cfgs_learnt_filtration.json'), 'w') as fid:\n",
    "    json.dump(exp_cfgs, fid)\n",
    "\n",
    "    \n",
    "exp_cfgs = combine(dataset_names, \n",
    "                   training_cfgs,\n",
    "                   model_cfgs_GIN)\n",
    "print(len(exp_cfgs))\n",
    "with open(os.path.join(output_dir, 'exp_cfgs_learnt_filtration.json'), 'w') as fid:\n",
    "    json.dump(exp_cfgs, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
